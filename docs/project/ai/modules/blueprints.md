# Blueprints Module (`src/esper/blueprints/`)

## Overview

The blueprints module provides the architecture definition and management system for morphogenetic kernels. It defines the intermediate representation (BlueprintIR) that bridges high-level architectural concepts with compilable kernel implementations. The module includes a registry system, metadata tracking, and a library of pre-built architectural templates.

## Architecture Concepts

### BlueprintIR

BlueprintIR is the intermediate representation that describes neural network architectures in a way that can be:
- Generated by AI architects (Karn)
- Compiled to optimized kernels (Tezzeret)
- Validated for correctness and safety
- Tagged with performance characteristics
- Evolved through morphogenetic adaptation

### Blueprint Lifecycle

1. **Creation**: Generated by Karn or manually defined
2. **Registration**: Stored in the blueprint registry
3. **Validation**: Static analysis and constraint checking
4. **Compilation**: Transformed to TorchScript kernels
5. **Deployment**: Loaded into KasminaLayer seeds
6. **Evolution**: Modified based on performance feedback

## Files

### `__init__.py` - Module Initialization

**Purpose:** Exports core blueprint functionality.

**Contents:**
```python
"""
Blueprint system for morphogenetic kernel architectures.
"""

from .registry import BlueprintRegistry
from .metadata import BlueprintMetadata, BlueprintIR, NodeSpec, EdgeSpec

__all__ = [
    "BlueprintRegistry",
    "BlueprintMetadata", 
    "BlueprintIR",
    "NodeSpec",
    "EdgeSpec"
]
```

### `metadata.py` - Blueprint Data Structures

**Purpose:** Defines the core data structures for representing neural network architectures.

#### Key Classes

**`NodeSpec`** - Graph Node Specification
```python
@dataclass
class NodeSpec:
    """
    Specification for a node in the blueprint graph.
    
    Represents a single operation in the neural network.
    """
    id: str
    op_type: str  # linear, conv2d, activation, normalization, etc.
    attributes: Dict[str, Any]
    
    # Shape information
    input_shape: Optional[List[int]] = None
    output_shape: Optional[List[int]] = None
    
    # Performance hints
    compute_intensity: float = 1.0  # FLOPs relative to baseline
    memory_bandwidth: float = 1.0   # Memory access pattern
    parallelism: str = "data"       # data, model, pipeline
    
    # Constraints
    requires_gpu: bool = False
    precision: str = "fp32"         # fp32, fp16, int8
    
    def validate(self) -> bool:
        """Validate node specification."""
        # Check required attributes for op_type
        required_attrs = self._get_required_attributes()
        for attr in required_attrs:
            if attr not in self.attributes:
                raise ValueError(f"Missing required attribute '{attr}' for op_type '{self.op_type}'")
        
        # Validate attribute values
        return self._validate_attributes()
    
    def estimate_flops(self) -> int:
        """Estimate FLOPs for this operation."""
        if self.op_type == "linear":
            in_features = self.attributes["in_features"]
            out_features = self.attributes["out_features"]
            return 2 * in_features * out_features  # MAC operations
        elif self.op_type == "conv2d":
            return self._estimate_conv2d_flops()
        # ... more operation types
        return 0
```

**`EdgeSpec`** - Graph Edge Specification
```python
@dataclass
class EdgeSpec:
    """
    Specification for an edge in the blueprint graph.
    
    Represents data flow between operations.
    """
    id: str
    source: str  # Source node ID
    target: str  # Target node ID
    
    # Data flow properties
    tensor_shape: Optional[List[int]] = None
    dtype: str = "float32"
    
    # Connection type
    connection_type: str = "forward"  # forward, residual, attention
    
    # Optional transformation
    transform: Optional[Dict[str, Any]] = None
```

**`BlueprintIR`** - Blueprint Intermediate Representation
```python
@dataclass
class BlueprintIR:
    """
    Intermediate representation of a neural network architecture.
    
    This is the core data structure that flows through the system.
    """
    id: str
    name: str
    version: int = 1
    
    # Graph structure
    nodes: List[NodeSpec]
    edges: List[EdgeSpec]
    
    # Metadata
    tags: List[str] = field(default_factory=list)
    author: str = "system"
    created_at: datetime = field(default_factory=lambda: datetime.now(UTC))
    
    # Performance characteristics
    estimated_flops: Optional[int] = None
    estimated_parameters: Optional[int] = None
    estimated_memory_mb: Optional[float] = None
    
    # Constraints and requirements
    min_compute_capability: Optional[float] = None  # CUDA compute capability
    requires_features: List[str] = field(default_factory=list)  # Required hardware features
    
    # Lineage tracking
    parent_id: Optional[str] = None
    mutation_type: Optional[str] = None  # crossover, mutation, optimization
    
    def to_dict(self) -> Dict[str, Any]:
        """Serialize to dictionary."""
        return {
            "id": self.id,
            "name": self.name,
            "version": self.version,
            "nodes": [asdict(node) for node in self.nodes],
            "edges": [asdict(edge) for edge in self.edges],
            "tags": self.tags,
            "metadata": {
                "author": self.author,
                "created_at": self.created_at.isoformat(),
                "estimated_flops": self.estimated_flops,
                "estimated_parameters": self.estimated_parameters,
                "estimated_memory_mb": self.estimated_memory_mb,
                "parent_id": self.parent_id,
                "mutation_type": self.mutation_type,
            }
        }
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "BlueprintIR":
        """Deserialize from dictionary."""
        nodes = [NodeSpec(**node) for node in data["nodes"]]
        edges = [EdgeSpec(**edge) for edge in data["edges"]]
        
        metadata = data.get("metadata", {})
        
        return cls(
            id=data["id"],
            name=data["name"],
            version=data.get("version", 1),
            nodes=nodes,
            edges=edges,
            tags=data.get("tags", []),
            author=metadata.get("author", "system"),
            created_at=datetime.fromisoformat(metadata.get("created_at", datetime.now(UTC).isoformat())),
            estimated_flops=metadata.get("estimated_flops"),
            estimated_parameters=metadata.get("estimated_parameters"),
            estimated_memory_mb=metadata.get("estimated_memory_mb"),
            parent_id=metadata.get("parent_id"),
            mutation_type=metadata.get("mutation_type"),
        )
    
    def validate(self) -> bool:
        """Validate blueprint structure and constraints."""
        # Validate all nodes
        for node in self.nodes:
            if not node.validate():
                return False
        
        # Validate graph connectivity
        node_ids = {node.id for node in self.nodes}
        for edge in self.edges:
            if edge.source not in node_ids:
                raise ValueError(f"Edge source '{edge.source}' not found in nodes")
            if edge.target not in node_ids:
                raise ValueError(f"Edge target '{edge.target}' not found in nodes")
        
        # Check for cycles (if acyclic is required)
        if self._has_cycles():
            raise ValueError("Blueprint contains cycles")
        
        # Validate shape compatibility
        return self._validate_shapes()
    
    def optimize(self) -> "BlueprintIR":
        """Apply graph optimizations."""
        # Common subexpression elimination
        # Constant folding
        # Dead code elimination
        # Fusion opportunities
        # Return optimized copy
        return self  # Placeholder
    
    def estimate_performance(self) -> Dict[str, float]:
        """Estimate performance characteristics."""
        total_flops = sum(node.estimate_flops() for node in self.nodes)
        total_params = sum(self._estimate_node_params(node) for node in self.nodes)
        
        # Memory estimation (activations + parameters)
        memory_mb = self._estimate_memory_usage()
        
        return {
            "flops": total_flops,
            "parameters": total_params,
            "memory_mb": memory_mb,
            "compute_intensity": total_flops / max(memory_mb * 1e6, 1),  # FLOPs per byte
        }
```

**`BlueprintMetadata`** - Extended Metadata
```python
@dataclass
class BlueprintMetadata:
    """
    Extended metadata for blueprint tracking and analysis.
    """
    blueprint_id: str
    
    # Performance benchmarks
    benchmarks: Dict[str, Dict[str, float]] = field(default_factory=dict)
    # e.g., {"gpu_v100": {"latency_ms": 1.2, "throughput": 1000}}
    
    # Validation results
    validation_passed: bool = True
    validation_errors: List[str] = field(default_factory=list)
    safety_score: float = 1.0  # 0-1 safety rating
    
    # Usage statistics
    deployment_count: int = 0
    success_rate: float = 0.0
    average_improvement: float = 0.0
    
    # Related blueprints
    similar_blueprints: List[str] = field(default_factory=list)
    derived_blueprints: List[str] = field(default_factory=list)
    
    # Training data
    training_metrics: Dict[str, Any] = field(default_factory=dict)
    hyperparameters: Dict[str, Any] = field(default_factory=dict)
```

### `registry.py` - Blueprint Registry

**Purpose:** Manages the collection of blueprints with search and versioning capabilities.

#### Key Classes

**`BlueprintRegistry`** - Central Blueprint Repository
```python
class BlueprintRegistry:
    """
    Central registry for managing blueprints.
    
    Features:
    - CRUD operations
    - Tag-based search
    - Version management
    - Performance tracking
    - Lineage tracking
    """
    
    def __init__(self, storage_path: Optional[str] = None):
        self.storage_path = storage_path or "./blueprint_registry"
        self.blueprints: Dict[str, BlueprintIR] = {}
        self.metadata: Dict[str, BlueprintMetadata] = {}
        self.index: Dict[str, Set[str]] = defaultdict(set)  # tag -> blueprint_ids
        
        # Performance cache
        self.performance_cache: Dict[str, Dict[str, float]] = {}
        
        # Load existing blueprints
        if os.path.exists(self.storage_path):
            self._load_from_disk()
    
    def register(self, blueprint: BlueprintIR) -> str:
        """
        Register a new blueprint.
        
        Returns:
            Blueprint ID
        """
        # Validate blueprint
        if not blueprint.validate():
            raise ValueError("Blueprint validation failed")
        
        # Check for duplicates
        existing_id = self._find_duplicate(blueprint)
        if existing_id:
            logger.info(f"Blueprint already exists with ID: {existing_id}")
            return existing_id
        
        # Generate ID if needed
        if not blueprint.id:
            blueprint.id = self._generate_id(blueprint)
        
        # Store blueprint
        self.blueprints[blueprint.id] = blueprint
        
        # Initialize metadata
        self.metadata[blueprint.id] = BlueprintMetadata(
            blueprint_id=blueprint.id,
            validation_passed=True
        )
        
        # Update indices
        self._update_indices(blueprint)
        
        # Persist to disk
        self._save_blueprint(blueprint)
        
        logger.info(f"Registered blueprint: {blueprint.id}")
        return blueprint.id
    
    def get(self, blueprint_id: str) -> Optional[BlueprintIR]:
        """Get blueprint by ID."""
        return self.blueprints.get(blueprint_id)
    
    def search_by_tags(
        self,
        tags: List[str],
        match_all: bool = False
    ) -> List[BlueprintIR]:
        """
        Search blueprints by tags.
        
        Args:
            tags: Tags to search for
            match_all: If True, blueprint must have all tags
            
        Returns:
            List of matching blueprints
        """
        if match_all:
            # Intersection of all tag sets
            blueprint_ids = set.intersection(
                *[self.index.get(tag, set()) for tag in tags]
            )
        else:
            # Union of all tag sets
            blueprint_ids = set.union(
                *[self.index.get(tag, set()) for tag in tags]
            )
        
        return [
            self.blueprints[bid] 
            for bid in blueprint_ids 
            if bid in self.blueprints
        ]
    
    def search_by_performance(
        self,
        metric: str,
        min_value: Optional[float] = None,
        max_value: Optional[float] = None
    ) -> List[BlueprintIR]:
        """
        Search blueprints by performance metrics.
        
        Args:
            metric: Performance metric name (e.g., "latency_ms", "throughput")
            min_value: Minimum acceptable value
            max_value: Maximum acceptable value
            
        Returns:
            List of matching blueprints
        """
        results = []
        
        for blueprint_id, metrics in self.performance_cache.items():
            if metric in metrics:
                value = metrics[metric]
                if min_value is not None and value < min_value:
                    continue
                if max_value is not None and value > max_value:
                    continue
                results.append(self.blueprints[blueprint_id])
        
        # Sort by performance (ascending for latency, descending for throughput)
        if metric in ["latency", "latency_ms", "memory_mb"]:
            results.sort(key=lambda b: self.performance_cache.get(b.id, {}).get(metric, float('inf')))
        else:
            results.sort(key=lambda b: self.performance_cache.get(b.id, {}).get(metric, 0), reverse=True)
        
        return results
    
    def get_lineage(self, blueprint_id: str) -> List[BlueprintIR]:
        """
        Get the lineage of a blueprint (ancestors).
        
        Returns blueprints from root to current.
        """
        lineage = []
        current_id = blueprint_id
        
        while current_id and current_id in self.blueprints:
            blueprint = self.blueprints[current_id]
            lineage.append(blueprint)
            current_id = blueprint.parent_id
        
        return list(reversed(lineage))
    
    def get_descendants(self, blueprint_id: str) -> List[BlueprintIR]:
        """Get all blueprints derived from this one."""
        descendants = []
        
        for blueprint in self.blueprints.values():
            if blueprint.parent_id == blueprint_id:
                descendants.append(blueprint)
                # Recursively get descendants
                descendants.extend(self.get_descendants(blueprint.id))
        
        return descendants
    
    def update_performance(
        self,
        blueprint_id: str,
        metrics: Dict[str, float],
        device: str = "default"
    ):
        """Update performance metrics for a blueprint."""
        if blueprint_id not in self.metadata:
            logger.warning(f"Blueprint {blueprint_id} not found")
            return
        
        # Update metadata
        metadata = self.metadata[blueprint_id]
        if device not in metadata.benchmarks:
            metadata.benchmarks[device] = {}
        metadata.benchmarks[device].update(metrics)
        
        # Update cache
        self.performance_cache[blueprint_id] = metrics
        
        # Persist
        self._save_metadata(metadata)
    
    def evolve(
        self,
        parent_id: str,
        mutations: List[Dict[str, Any]],
        mutation_type: str = "optimization"
    ) -> str:
        """
        Create evolved version of blueprint.
        
        Args:
            parent_id: Parent blueprint ID
            mutations: List of mutations to apply
            mutation_type: Type of evolution (optimization, crossover, etc.)
            
        Returns:
            New blueprint ID
        """
        parent = self.get(parent_id)
        if not parent:
            raise ValueError(f"Parent blueprint {parent_id} not found")
        
        # Create copy
        evolved = copy.deepcopy(parent)
        evolved.id = self._generate_id(evolved)
        evolved.version = parent.version + 1
        evolved.parent_id = parent_id
        evolved.mutation_type = mutation_type
        
        # Apply mutations
        for mutation in mutations:
            self._apply_mutation(evolved, mutation)
        
        # Validate
        if not evolved.validate():
            raise ValueError("Evolved blueprint validation failed")
        
        # Register
        return self.register(evolved)
    
    def export_manifest(self) -> Dict[str, Any]:
        """Export registry manifest for distribution."""
        return {
            "version": "1.0",
            "blueprints": [
                {
                    "id": b.id,
                    "name": b.name,
                    "tags": b.tags,
                    "performance": self.performance_cache.get(b.id, {}),
                    "metadata": asdict(self.metadata.get(b.id, BlueprintMetadata(b.id)))
                }
                for b in self.blueprints.values()
            ],
            "statistics": {
                "total_blueprints": len(self.blueprints),
                "total_tags": len(self.index),
                "average_performance": self._calculate_average_performance(),
            }
        }
```

### `manifest.yaml` - Registry Manifest

**Purpose:** Defines the structure and metadata for the blueprint registry.

**Contents:**
```yaml
# Blueprint Registry Manifest
version: "1.0"
name: "Esper Blueprint Registry"
description: "Central registry for morphogenetic kernel blueprints"

# Registry configuration
registry:
  storage_backend: "filesystem"  # filesystem, s3, database
  index_type: "memory"          # memory, redis, elasticsearch
  
# Blueprint categories
categories:
  - name: "attention"
    description: "Attention mechanisms and transformers"
    tags: ["attention", "transformer", "self-attention"]
    
  - name: "efficiency"
    description: "Efficiency-optimized architectures"
    tags: ["efficient", "mobile", "pruned", "quantized"]
    
  - name: "specialized"
    description: "Task-specific architectures"
    tags: ["vision", "nlp", "audio", "multimodal"]
    
  - name: "experimental"
    description: "Research and experimental architectures"
    tags: ["research", "experimental", "novel"]

# Validation rules
validation:
  max_nodes: 1000
  max_edges: 5000
  max_depth: 100
  allowed_op_types:
    - linear
    - conv2d
    - activation
    - normalization
    - pooling
    - attention
    - embedding
    - recurrent
    
# Performance benchmarks
benchmarks:
  devices:
    - name: "cpu"
      description: "CPU execution"
      
    - name: "gpu_v100"
      description: "NVIDIA V100 GPU"
      
    - name: "gpu_a100"
      description: "NVIDIA A100 GPU"
      
  metrics:
    - name: "latency_ms"
      description: "Execution latency in milliseconds"
      
    - name: "throughput"
      description: "Throughput in operations/second"
      
    - name: "memory_mb"
      description: "Memory usage in megabytes"
      
    - name: "energy_mj"
      description: "Energy consumption in millijoules"
```

### `templates/` - Pre-built Blueprint Templates

The templates directory contains pre-built architectural patterns that can be instantiated and customized.

### `templates/__init__.py`

```python
"""Blueprint templates for common architectural patterns."""

from .transformer import create_transformer_block, create_attention_head
from .efficiency import create_mobilenet_block, create_squeezenet_fire
from .moe import create_moe_layer, create_expert_network
from .routing import create_dynamic_routing, create_conditional_computation
from .diagnostics import create_probe_layer, create_gradient_analyzer

__all__ = [
    "create_transformer_block",
    "create_attention_head", 
    "create_mobilenet_block",
    "create_squeezenet_fire",
    "create_moe_layer",
    "create_expert_network",
    "create_dynamic_routing",
    "create_conditional_computation",
    "create_probe_layer",
    "create_gradient_analyzer",
]
```

### `templates/transformer.py` - Transformer Templates

**Purpose:** Templates for transformer-based architectures.

```python
def create_transformer_block(
    d_model: int = 512,
    n_heads: int = 8,
    d_ff: int = 2048,
    dropout: float = 0.1,
    activation: str = "relu",
    pre_norm: bool = True
) -> BlueprintIR:
    """
    Create a transformer block blueprint.
    
    Args:
        d_model: Model dimension
        n_heads: Number of attention heads
        d_ff: Feed-forward dimension
        dropout: Dropout rate
        activation: Activation function
        pre_norm: Use pre-normalization (vs post-norm)
        
    Returns:
        BlueprintIR for transformer block
    """
    nodes = []
    edges = []
    
    # Input node
    nodes.append(NodeSpec(
        id="input",
        op_type="input",
        attributes={"shape": [-1, -1, d_model]}
    ))
    
    # Pre-norm or post-norm
    if pre_norm:
        # LayerNorm before attention
        nodes.append(NodeSpec(
            id="norm1",
            op_type="normalization",
            attributes={"type": "layer_norm", "normalized_shape": [d_model]}
        ))
        edges.append(EdgeSpec(id="e1", source="input", target="norm1"))
        attn_input = "norm1"
    else:
        attn_input = "input"
    
    # Multi-head attention
    nodes.append(NodeSpec(
        id="attention",
        op_type="attention",
        attributes={
            "embed_dim": d_model,
            "num_heads": n_heads,
            "dropout": dropout,
            "bias": True,
            "batch_first": True
        },
        compute_intensity=4.0  # Attention is compute intensive
    ))
    edges.append(EdgeSpec(id="e2", source=attn_input, target="attention"))
    
    # Residual connection
    nodes.append(NodeSpec(
        id="residual1",
        op_type="add",
        attributes={}
    ))
    edges.append(EdgeSpec(id="e3", source="attention", target="residual1"))
    edges.append(EdgeSpec(
        id="e4", 
        source="input", 
        target="residual1",
        connection_type="residual"
    ))
    
    # Second norm
    if pre_norm:
        nodes.append(NodeSpec(
            id="norm2",
            op_type="normalization",
            attributes={"type": "layer_norm", "normalized_shape": [d_model]}
        ))
        edges.append(EdgeSpec(id="e5", source="residual1", target="norm2"))
        ff_input = "norm2"
    else:
        # Post-norm after residual
        nodes.append(NodeSpec(
            id="norm1_post",
            op_type="normalization",
            attributes={"type": "layer_norm", "normalized_shape": [d_model]}
        ))
        edges.append(EdgeSpec(id="e5", source="residual1", target="norm1_post"))
        ff_input = "norm1_post"
    
    # Feed-forward network
    nodes.extend([
        NodeSpec(
            id="ff1",
            op_type="linear",
            attributes={"in_features": d_model, "out_features": d_ff}
        ),
        NodeSpec(
            id="activation",
            op_type="activation",
            attributes={"type": activation}
        ),
        NodeSpec(
            id="dropout",
            op_type="dropout",
            attributes={"p": dropout}
        ),
        NodeSpec(
            id="ff2",
            op_type="linear",
            attributes={"in_features": d_ff, "out_features": d_model}
        )
    ])
    
    # FF connections
    edges.extend([
        EdgeSpec(id="e6", source=ff_input, target="ff1"),
        EdgeSpec(id="e7", source="ff1", target="activation"),
        EdgeSpec(id="e8", source="activation", target="dropout"),
        EdgeSpec(id="e9", source="dropout", target="ff2")
    ])
    
    # Second residual
    nodes.append(NodeSpec(
        id="residual2",
        op_type="add",
        attributes={}
    ))
    edges.append(EdgeSpec(id="e10", source="ff2", target="residual2"))
    edges.append(EdgeSpec(
        id="e11",
        source="residual1",
        target="residual2", 
        connection_type="residual"
    ))
    
    # Final norm if post-norm
    if not pre_norm:
        nodes.append(NodeSpec(
            id="norm2_post",
            op_type="normalization",
            attributes={"type": "layer_norm", "normalized_shape": [d_model]}
        ))
        edges.append(EdgeSpec(id="e12", source="residual2", target="norm2_post"))
        output = "norm2_post"
    else:
        output = "residual2"
    
    # Output node
    nodes.append(NodeSpec(
        id="output",
        op_type="output",
        attributes={}
    ))
    edges.append(EdgeSpec(id="e13", source=output, target="output"))
    
    # Create blueprint
    blueprint = BlueprintIR(
        id=f"transformer_block_{d_model}_{n_heads}",
        name=f"Transformer Block (d={d_model}, h={n_heads})",
        nodes=nodes,
        edges=edges,
        tags=["transformer", "attention", "feedforward", "residual"]
    )
    
    # Estimate performance
    perf = blueprint.estimate_performance()
    blueprint.estimated_flops = perf["flops"]
    blueprint.estimated_parameters = perf["parameters"]
    blueprint.estimated_memory_mb = perf["memory_mb"]
    
    return blueprint
```

### `templates/efficiency.py` - Efficiency Templates

**Purpose:** Templates for efficient architectures (MobileNet, SqueezeNet, etc).

```python
def create_mobilenet_block(
    in_channels: int,
    out_channels: int,
    stride: int = 1,
    expand_ratio: int = 6,
    kernel_size: int = 3,
    use_se: bool = True,
    se_ratio: float = 0.25
) -> BlueprintIR:
    """
    Create a MobileNetV3 block blueprint.
    
    Implements inverted residual with depthwise separable convolutions
    and optional squeeze-and-excitation.
    """
    nodes = []
    edges = []
    
    # Expansion dimension
    expanded_channels = in_channels * expand_ratio
    
    # Input
    nodes.append(NodeSpec(
        id="input",
        op_type="input",
        attributes={"shape": [-1, in_channels, -1, -1]}
    ))
    
    # Expansion layer (1x1 conv)
    if expand_ratio != 1:
        nodes.append(NodeSpec(
            id="expand",
            op_type="conv2d",
            attributes={
                "in_channels": in_channels,
                "out_channels": expanded_channels,
                "kernel_size": 1,
                "bias": False
            },
            compute_intensity=0.1  # 1x1 conv is cheap
        ))
        edges.append(EdgeSpec(id="e1", source="input", target="expand"))
        
        # BatchNorm + Activation
        nodes.extend([
            NodeSpec(
                id="bn1",
                op_type="normalization",
                attributes={"type": "batch_norm", "num_features": expanded_channels}
            ),
            NodeSpec(
                id="act1",
                op_type="activation",
                attributes={"type": "hardswish"}
            )
        ])
        edges.extend([
            EdgeSpec(id="e2", source="expand", target="bn1"),
            EdgeSpec(id="e3", source="bn1", target="act1")
        ])
        dw_input = "act1"
    else:
        dw_input = "input"
        expanded_channels = in_channels
    
    # Depthwise convolution
    nodes.append(NodeSpec(
        id="depthwise",
        op_type="conv2d",
        attributes={
            "in_channels": expanded_channels,
            "out_channels": expanded_channels,
            "kernel_size": kernel_size,
            "stride": stride,
            "padding": kernel_size // 2,
            "groups": expanded_channels,  # Depthwise
            "bias": False
        },
        compute_intensity=0.2  # Depthwise is efficient
    ))
    edges.append(EdgeSpec(id="e4", source=dw_input, target="depthwise"))
    
    # BatchNorm + Activation
    nodes.extend([
        NodeSpec(
            id="bn2",
            op_type="normalization",
            attributes={"type": "batch_norm", "num_features": expanded_channels}
        ),
        NodeSpec(
            id="act2",
            op_type="activation",
            attributes={"type": "hardswish"}
        )
    ])
    edges.extend([
        EdgeSpec(id="e5", source="depthwise", target="bn2"),
        EdgeSpec(id="e6", source="bn2", target="act2")
    ])
    
    se_output = "act2"
    
    # Squeeze-and-excitation
    if use_se:
        se_channels = int(expanded_channels * se_ratio)
        nodes.extend([
            NodeSpec(
                id="se_pool",
                op_type="pooling",
                attributes={"type": "adaptive_avg_pool2d", "output_size": 1}
            ),
            NodeSpec(
                id="se_fc1",
                op_type="linear",
                attributes={
                    "in_features": expanded_channels,
                    "out_features": se_channels
                }
            ),
            NodeSpec(
                id="se_act",
                op_type="activation",
                attributes={"type": "relu"}
            ),
            NodeSpec(
                id="se_fc2",
                op_type="linear",
                attributes={
                    "in_features": se_channels,
                    "out_features": expanded_channels
                }
            ),
            NodeSpec(
                id="se_sigmoid",
                op_type="activation",
                attributes={"type": "hardsigmoid"}
            ),
            NodeSpec(
                id="se_mul",
                op_type="multiply",
                attributes={}
            )
        ])
        
        edges.extend([
            EdgeSpec(id="e7", source="act2", target="se_pool"),
            EdgeSpec(id="e8", source="se_pool", target="se_fc1"),
            EdgeSpec(id="e9", source="se_fc1", target="se_act"),
            EdgeSpec(id="e10", source="se_act", target="se_fc2"),
            EdgeSpec(id="e11", source="se_fc2", target="se_sigmoid"),
            EdgeSpec(id="e12", source="act2", target="se_mul"),
            EdgeSpec(id="e13", source="se_sigmoid", target="se_mul")
        ])
        se_output = "se_mul"
    
    # Projection layer (1x1 conv)
    nodes.append(NodeSpec(
        id="project",
        op_type="conv2d",
        attributes={
            "in_channels": expanded_channels,
            "out_channels": out_channels,
            "kernel_size": 1,
            "bias": False
        },
        compute_intensity=0.1
    ))
    edges.append(EdgeSpec(id="e14", source=se_output, target="project"))
    
    nodes.append(NodeSpec(
        id="bn3",
        op_type="normalization",
        attributes={"type": "batch_norm", "num_features": out_channels}
    ))
    edges.append(EdgeSpec(id="e15", source="project", target="bn3"))
    
    # Residual connection (if applicable)
    if stride == 1 and in_channels == out_channels:
        nodes.append(NodeSpec(
            id="residual",
            op_type="add",
            attributes={}
        ))
        edges.extend([
            EdgeSpec(id="e16", source="bn3", target="residual"),
            EdgeSpec(id="e17", source="input", target="residual", connection_type="residual")
        ])
        output = "residual"
    else:
        output = "bn3"
    
    # Output
    nodes.append(NodeSpec(
        id="output",
        op_type="output",
        attributes={}
    ))
    edges.append(EdgeSpec(id="e18", source=output, target="output"))
    
    # Create blueprint
    blueprint = BlueprintIR(
        id=f"mobilenet_block_{in_channels}_{out_channels}_s{stride}",
        name=f"MobileNet Block ({in_channels}->{out_channels}, s={stride})",
        nodes=nodes,
        edges=edges,
        tags=["efficient", "mobile", "depthwise", "inverted_residual"]
    )
    
    return blueprint
```

### `templates/moe.py` - Mixture of Experts Templates

**Purpose:** Templates for mixture of experts architectures.

```python
def create_moe_layer(
    input_dim: int,
    output_dim: int,
    num_experts: int = 8,
    expert_capacity: float = 1.25,
    top_k: int = 2,
    noise_std: float = 0.1
) -> BlueprintIR:
    """
    Create a Mixture of Experts (MoE) layer blueprint.
    
    Args:
        input_dim: Input dimension
        output_dim: Output dimension  
        num_experts: Number of expert networks
        expert_capacity: Capacity factor for load balancing
        top_k: Number of experts to activate per input
        noise_std: Standard deviation of gating noise
        
    Returns:
        BlueprintIR for MoE layer
    """
    nodes = []
    edges = []
    
    # Input
    nodes.append(NodeSpec(
        id="input",
        op_type="input",
        attributes={"shape": [-1, input_dim]}
    ))
    
    # Gating network
    nodes.append(NodeSpec(
        id="gate_linear",
        op_type="linear",
        attributes={
            "in_features": input_dim,
            "out_features": num_experts
        }
    ))
    edges.append(EdgeSpec(id="e1", source="input", target="gate_linear"))
    
    # Add noise for load balancing
    nodes.append(NodeSpec(
        id="gate_noise",
        op_type="noise",
        attributes={"std": noise_std, "training_only": True}
    ))
    edges.append(EdgeSpec(id="e2", source="gate_linear", target="gate_noise"))
    
    # Top-k gating
    nodes.append(NodeSpec(
        id="topk_gate",
        op_type="topk_gating",
        attributes={
            "k": top_k,
            "capacity_factor": expert_capacity
        }
    ))
    edges.append(EdgeSpec(id="e3", source="gate_noise", target="topk_gate"))
    
    # Expert networks
    expert_outputs = []
    for i in range(num_experts):
        # Each expert is a simple FFN
        nodes.extend([
            NodeSpec(
                id=f"expert{i}_linear1",
                op_type="linear",
                attributes={
                    "in_features": input_dim,
                    "out_features": output_dim * 4  # Expansion
                }
            ),
            NodeSpec(
                id=f"expert{i}_act",
                op_type="activation",
                attributes={"type": "gelu"}
            ),
            NodeSpec(
                id=f"expert{i}_linear2",
                op_type="linear",
                attributes={
                    "in_features": output_dim * 4,
                    "out_features": output_dim
                }
            )
        ])
        
        # Connect expert
        edges.extend([
            EdgeSpec(id=f"e_exp{i}_1", source="input", target=f"expert{i}_linear1"),
            EdgeSpec(id=f"e_exp{i}_2", source=f"expert{i}_linear1", target=f"expert{i}_act"),
            EdgeSpec(id=f"e_exp{i}_3", source=f"expert{i}_act", target=f"expert{i}_linear2")
        ])
        
        expert_outputs.append(f"expert{i}_linear2")
    
    # Combine experts
    nodes.append(NodeSpec(
        id="combine_experts",
        op_type="moe_combine",
        attributes={
            "num_experts": num_experts,
            "top_k": top_k
        }
    ))
    
    # Connect gating and expert outputs to combiner
    edges.append(EdgeSpec(id="e_gate", source="topk_gate", target="combine_experts"))
    for i, expert_out in enumerate(expert_outputs):
        edges.append(EdgeSpec(
            id=f"e_combine_{i}",
            source=expert_out,
            target="combine_experts"
        ))
    
    # Auxiliary loss for load balancing
    nodes.append(NodeSpec(
        id="aux_loss",
        op_type="moe_aux_loss",
        attributes={"loss_coef": 0.01}
    ))
    edges.append(EdgeSpec(id="e_aux", source="topk_gate", target="aux_loss"))
    
    # Output
    nodes.append(NodeSpec(
        id="output",
        op_type="output",
        attributes={}
    ))
    edges.append(EdgeSpec(id="e_out", source="combine_experts", target="output"))
    
    # Create blueprint
    blueprint = BlueprintIR(
        id=f"moe_layer_{num_experts}x_{top_k}",
        name=f"MoE Layer ({num_experts} experts, top-{top_k})",
        nodes=nodes,
        edges=edges,
        tags=["moe", "sparse", "conditional", "scalable"]
    )
    
    return blueprint
```

### `templates/routing.py` - Dynamic Routing Templates

**Purpose:** Templates for dynamic and conditional computation.

```python
def create_dynamic_routing(
    input_dim: int,
    num_paths: int = 4,
    routing_temperature: float = 1.0,
    hard_routing: bool = False
) -> BlueprintIR:
    """
    Create a dynamic routing layer blueprint.
    
    Routes inputs through different paths based on learned routing.
    """
    nodes = []
    edges = []
    
    # Input
    nodes.append(NodeSpec(
        id="input",
        op_type="input",
        attributes={"shape": [-1, input_dim]}
    ))
    
    # Router network
    nodes.extend([
        NodeSpec(
            id="router_linear",
            op_type="linear",
            attributes={
                "in_features": input_dim,
                "out_features": num_paths
            }
        ),
        NodeSpec(
            id="router_softmax",
            op_type="activation",
            attributes={
                "type": "softmax",
                "temperature": routing_temperature,
                "hard": hard_routing  # Gumbel-softmax for discrete routing
            }
        )
    ])
    
    edges.extend([
        EdgeSpec(id="e1", source="input", target="router_linear"),
        EdgeSpec(id="e2", source="router_linear", target="router_softmax")
    ])
    
    # Path networks (each with different characteristics)
    path_outputs = []
    
    # Path 1: High capacity
    nodes.extend([
        NodeSpec(
            id="path1_linear",
            op_type="linear",
            attributes={
                "in_features": input_dim,
                "out_features": input_dim * 2
            },
            compute_intensity=2.0
        ),
        NodeSpec(id="path1_act", op_type="activation", attributes={"type": "relu"})
    ])
    edges.extend([
        EdgeSpec(id="e_p1_1", source="input", target="path1_linear"),
        EdgeSpec(id="e_p1_2", source="path1_linear", target="path1_act")
    ])
    path_outputs.append("path1_act")
    
    # Path 2: Efficient
    nodes.append(NodeSpec(
        id="path2_linear",
        op_type="linear",
        attributes={
            "in_features": input_dim,
            "out_features": input_dim // 2
        },
        compute_intensity=0.5
    ))
    edges.append(EdgeSpec(id="e_p2_1", source="input", target="path2_linear"))
    path_outputs.append("path2_linear")
    
    # Path 3: Identity (skip)
    nodes.append(NodeSpec(
        id="path3_identity",
        op_type="identity",
        attributes={},
        compute_intensity=0.0
    ))
    edges.append(EdgeSpec(id="e_p3_1", source="input", target="path3_identity"))
    path_outputs.append("path3_identity")
    
    # Path 4: Specialized (e.g., frequency domain)
    nodes.extend([
        NodeSpec(
            id="path4_fft",
            op_type="fft",
            attributes={"dim": -1},
            compute_intensity=1.5
        ),
        NodeSpec(
            id="path4_linear",
            op_type="linear",
            attributes={
                "in_features": input_dim,
                "out_features": input_dim
            }
        ),
        NodeSpec(
            id="path4_ifft",
            op_type="ifft",
            attributes={"dim": -1}
        )
    ])
    edges.extend([
        EdgeSpec(id="e_p4_1", source="input", target="path4_fft"),
        EdgeSpec(id="e_p4_2", source="path4_fft", target="path4_linear"),
        EdgeSpec(id="e_p4_3", source="path4_linear", target="path4_ifft")
    ])
    path_outputs.append("path4_ifft")
    
    # Weighted combination
    nodes.append(NodeSpec(
        id="combine",
        op_type="weighted_sum",
        attributes={"num_inputs": num_paths}
    ))
    
    # Connect router and paths to combiner
    edges.append(EdgeSpec(id="e_route", source="router_softmax", target="combine"))
    for i, path_out in enumerate(path_outputs):
        edges.append(EdgeSpec(
            id=f"e_combine_{i}",
            source=path_out,
            target="combine"
        ))
    
    # Output projection to match dimensions
    nodes.append(NodeSpec(
        id="output_proj",
        op_type="linear",
        attributes={
            "in_features": input_dim,  # Assuming paths output input_dim
            "out_features": input_dim
        }
    ))
    edges.append(EdgeSpec(id="e_proj", source="combine", target="output_proj"))
    
    # Output
    nodes.append(NodeSpec(
        id="output",
        op_type="output",
        attributes={}
    ))
    edges.append(EdgeSpec(id="e_out", source="output_proj", target="output"))
    
    # Create blueprint
    blueprint = BlueprintIR(
        id=f"dynamic_routing_{num_paths}paths",
        name=f"Dynamic Routing ({num_paths} paths)",
        nodes=nodes,
        edges=edges,
        tags=["routing", "conditional", "adaptive", "multi_path"]
    )
    
    return blueprint
```

### `templates/diagnostics.py` - Diagnostic Templates

**Purpose:** Templates for model introspection and debugging.

```python
def create_probe_layer(
    probe_type: str = "activation",
    reduction: str = "mean",
    detach: bool = True
) -> BlueprintIR:
    """
    Create a diagnostic probe layer blueprint.
    
    Non-invasive layer for monitoring internal activations.
    """
    nodes = []
    edges = []
    
    # Input
    nodes.append(NodeSpec(
        id="input",
        op_type="input",
        attributes={"shape": [-1, -1]}  # Flexible shape
    ))
    
    # Detach from computation graph if needed
    if detach:
        nodes.append(NodeSpec(
            id="detach",
            op_type="detach",
            attributes={}
        ))
        edges.append(EdgeSpec(id="e1", source="input", target="detach"))
        probe_input = "detach"
    else:
        probe_input = "input"
    
    # Probe computation
    if probe_type == "activation":
        # Activation statistics
        nodes.extend([
            NodeSpec(
                id="act_mean",
                op_type="reduce",
                attributes={"operation": "mean", "dim": -1}
            ),
            NodeSpec(
                id="act_std",
                op_type="reduce",
                attributes={"operation": "std", "dim": -1}
            ),
            NodeSpec(
                id="act_max",
                op_type="reduce",
                attributes={"operation": "max", "dim": -1}
            )
        ])
        edges.extend([
            EdgeSpec(id="e2", source=probe_input, target="act_mean"),
            EdgeSpec(id="e3", source=probe_input, target="act_std"),
            EdgeSpec(id="e4", source=probe_input, target="act_max")
        ])
        
        # Combine statistics
        nodes.append(NodeSpec(
            id="combine_stats",
            op_type="concat",
            attributes={"dim": -1}
        ))
        edges.extend([
            EdgeSpec(id="e5", source="act_mean", target="combine_stats"),
            EdgeSpec(id="e6", source="act_std", target="combine_stats"),
            EdgeSpec(id="e7", source="act_max", target="combine_stats")
        ])
        output_source = "combine_stats"
        
    elif probe_type == "gradient":
        # Gradient magnitude
        nodes.append(NodeSpec(
            id="grad_norm",
            op_type="gradient_norm",
            attributes={"ord": 2}
        ))
        edges.append(EdgeSpec(id="e2", source=probe_input, target="grad_norm"))
        output_source = "grad_norm"
        
    elif probe_type == "information":
        # Information content (entropy)
        nodes.extend([
            NodeSpec(
                id="softmax",
                op_type="activation",
                attributes={"type": "softmax", "dim": -1}
            ),
            NodeSpec(
                id="entropy",
                op_type="entropy",
                attributes={}
            )
        ])
        edges.extend([
            EdgeSpec(id="e2", source=probe_input, target="softmax"),
            EdgeSpec(id="e3", source="softmax", target="entropy")
        ])
        output_source = "entropy"
    
    # Reduction if specified
    if reduction != "none":
        nodes.append(NodeSpec(
            id="reduce",
            op_type="reduce",
            attributes={"operation": reduction, "dim": None}  # Global reduction
        ))
        edges.append(EdgeSpec(id="e_red", source=output_source, target="reduce"))
        output_source = "reduce"
    
    # Log to telemetry
    nodes.append(NodeSpec(
        id="telemetry",
        op_type="telemetry",
        attributes={
            "metric_name": f"{probe_type}_probe",
            "log_frequency": 100  # Log every 100 iterations
        }
    ))
    edges.append(EdgeSpec(id="e_tel", source=output_source, target="telemetry"))
    
    # Pass through original input
    nodes.append(NodeSpec(
        id="output",
        op_type="output",
        attributes={}
    ))
    edges.append(EdgeSpec(id="e_out", source="input", target="output"))
    
    # Create blueprint
    blueprint = BlueprintIR(
        id=f"probe_{probe_type}_{reduction}",
        name=f"Diagnostic Probe ({probe_type}, {reduction})",
        nodes=nodes,
        edges=edges,
        tags=["diagnostic", "probe", "monitoring", "non_invasive"]
    )
    
    # Probe has zero compute cost for main computation
    blueprint.estimated_flops = 0
    
    return blueprint
```

## Usage Examples

### Creating and Registering a Blueprint

```python
from esper.blueprints import BlueprintRegistry, BlueprintIR, NodeSpec, EdgeSpec

# Create registry
registry = BlueprintRegistry()

# Define a simple feedforward blueprint
nodes = [
    NodeSpec(
        id="input",
        op_type="input",
        attributes={"shape": [-1, 784]}
    ),
    NodeSpec(
        id="fc1",
        op_type="linear",
        attributes={"in_features": 784, "out_features": 256}
    ),
    NodeSpec(
        id="relu1",
        op_type="activation",
        attributes={"type": "relu"}
    ),
    NodeSpec(
        id="fc2",
        op_type="linear",
        attributes={"in_features": 256, "out_features": 10}
    ),
    NodeSpec(
        id="output",
        op_type="output",
        attributes={}
    )
]

edges = [
    EdgeSpec(id="e1", source="input", target="fc1"),
    EdgeSpec(id="e2", source="fc1", target="relu1"),
    EdgeSpec(id="e3", source="relu1", target="fc2"),
    EdgeSpec(id="e4", source="fc2", target="output")
]

blueprint = BlueprintIR(
    id="simple_mlp",
    name="Simple MLP",
    nodes=nodes,
    edges=edges,
    tags=["feedforward", "classification", "mnist"]
)

# Register blueprint
blueprint_id = registry.register(blueprint)
```

### Using Templates

```python
from esper.blueprints.templates import create_transformer_block, create_mobilenet_block

# Create transformer block
transformer = create_transformer_block(
    d_model=512,
    n_heads=8,
    d_ff=2048,
    dropout=0.1,
    pre_norm=True
)

# Register it
registry.register(transformer)

# Create efficient mobile block
mobile_block = create_mobilenet_block(
    in_channels=32,
    out_channels=64,
    stride=2,
    expand_ratio=6,
    use_se=True
)

registry.register(mobile_block)
```

### Searching and Retrieving Blueprints

```python
# Search by tags
attention_blueprints = registry.search_by_tags(
    tags=["attention", "transformer"],
    match_all=True
)

# Search by performance
efficient_blueprints = registry.search_by_performance(
    metric="latency_ms",
    max_value=5.0  # Less than 5ms latency
)

# Get blueprint lineage
lineage = registry.get_lineage("evolved_transformer_v3")
for blueprint in lineage:
    print(f"Generation {blueprint.version}: {blueprint.name}")
```

### Evolution and Mutation

```python
# Evolve a blueprint
mutations = [
    {
        "type": "modify_attribute",
        "node_id": "fc1",
        "attribute": "out_features",
        "value": 512  # Increase capacity
    },
    {
        "type": "add_node",
        "node": NodeSpec(
            id="dropout1",
            op_type="dropout",
            attributes={"p": 0.5}
        ),
        "after": "relu1"  # Insert after relu1
    }
]

evolved_id = registry.evolve(
    parent_id="simple_mlp",
    mutations=mutations,
    mutation_type="capacity_increase"
)
```

## Integration with Services

### Urza Integration

Blueprints are stored and retrieved from Urza:

```python
# Submit to Urza
response = await urza_client.submit_blueprint(
    BlueprintSubmissionRequest(
        name=blueprint.name,
        architecture_ir=json.dumps(blueprint.to_dict()),
        tags=blueprint.tags
    )
)
```

### Tezzeret Integration

Blueprints are compiled by Tezzeret:

```python
# Tezzeret polls for uncompiled blueprints
uncompiled = await urza_client.get_blueprints(status="unvalidated")

for blueprint_data in uncompiled:
    blueprint = BlueprintIR.from_dict(json.loads(blueprint_data.architecture_ir))
    
    # Compile to kernel
    kernel = await compiler.compile_blueprint(blueprint)
```

### Karn Integration

Karn generates new blueprints based on performance feedback:

```python
# Karn creates new architectures
new_blueprint = karn.generate_blueprint(
    task="classification",
    constraints={
        "max_latency_ms": 10,
        "max_memory_mb": 100
    },
    parent_blueprints=[high_performing_blueprint]
)

registry.register(new_blueprint)
```

## Performance Optimization

### Blueprint Optimization

The blueprint system includes several optimization passes:

1. **Graph Simplification**: Remove redundant nodes and edges
2. **Operator Fusion**: Combine compatible operations
3. **Constant Folding**: Pre-compute constant expressions
4. **Shape Inference**: Propagate shapes through the graph
5. **Memory Planning**: Optimize tensor allocation

### Compilation Hints

Blueprints include hints for the compiler:

- **Compute Intensity**: Guides scheduling decisions
- **Memory Patterns**: Helps with cache optimization
- **Parallelism**: Indicates parallelization opportunities
- **Precision**: Allows mixed-precision execution

## Future Enhancements

1. **Graph Neural Network Generation**: Use GNNs to generate blueprints
2. **AutoML Integration**: Automated architecture search
3. **Hardware-Aware Optimization**: Target-specific blueprints
4. **Cross-Blueprint Learning**: Transfer learning between architectures
5. **Symbolic Execution**: Formal verification of blueprints
6. **Differential Architecture Search**: Gradient-based architecture optimization